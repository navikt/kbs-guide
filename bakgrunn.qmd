# Bakgrunn

## Kunnskapsbase Baserte Språkmodeller

Kunnskapsbase Baserte Språkmodeller (_KBS_), oversatt fra [Retrieval-Augmented
Generation][wiki_rag], er en teknikk for å inkorporere ekstern eller ny
informasjon når en stor språkmodell skal generere svar. Uten _KBS_ vil en stor
språkmodell generere svaret sitt basert på informasjon den plukket opp under
opptrening. Bakdelen med dette er at det tar lang tid å trene opp samtidig som
opptrening er en kostbar prosess. Med _KBS_ bruker vi deler av
[kontekstvinduet][openai_token] til å fylle inn informasjon fra en
kunnskapsbase. Dette gjør at kunnskapsbasen og språkmodellen kan utvikle seg
uavhengig av hverandre og kunnskapsbasen kan oppdateres med ny informasjon uten
at språkmodellen trenger å endre seg.

I @fig-rag-overview er det illustrert hvordan flyten går fra bruker stiller
spørsmål til språkmodellen som benytter både spørsmålet samt relevante
dokumenter som input for å generere et svar.

![Illustrasjon av Kunnskapsbase Baserte Språkmodeller. Språkmodellen tar som
input både spørsmålet fra brukeren og relevante dokumenter som finnes i
kunnskapsbasen.](assets/images/rag_overview.png){#fig-rag-overview}

En utfordring med _KBS_ er hvordan man skal organisere kunnskapsbasen slik at
relevante dokumenter kan inkorporeres i konteksten til den store språkmodellen.
Hvordan søket utføres vil ha stor innvirkning på kvaliteten på det genererte
svaret ettersom _KBS_ ofte krever at språkmodellen bare svarer på bakgrunn av
dokumentene i konteksten. I teorien er det ikke noe i veien for å bruke et mer
tradisjonelt søk etter dokumenter, ala Google søk. I oppsettet til Azure er det
derimot satt opp til at man bruker en vektordatabase som finner relevante
dokumenter[^1].

## Vektordatabase

I konteksten av _KBS_ er en vektordatabase en måte å lagre en indeks over
dokumenter som sammenfaller med måten språkmodellen forstår tekst. Som navnet
tilsier er en vektordatabase en database med vektorer, det spesielle i
konteksten av _KBS_ er at disse vektorene er generert med samme modell som
språkmodellen bruker å oversette tekst til tall. Med andre ord, dokumentene i
kunnskapsbasen indekseres med en feature vektor av inneholde deres, generert fra
en [embedding modell][wiki_embedding].

I @fig-rag-vector-database er det illustrert hvordan kunnskapsbasen og
vektordatabasen henger sammen for å hente frem relevant kontekst for
spårkmodellen. I figuren vises sammenhengen mellom embedding modellen og
vektordatabasen, både indeksen til vektordatabasen blir laget på bakgrunn av
embedding modellen samtidig som spørsmålet til brukeren går gjennom embedding
modellen for å søke i vektordatabasen.

![Kunnskapsbase Baserte Språkmodeller med vektordatabase. I grått på
illustrasjonen er det prøvd å vise hvordan vektordatabasen oppdateres fra
kunnskapsbasen. Oppdateringen skjer uavhengig av
språkmodellen.](assets/images/rag_vector_database.png){#fig-rag-vector-database}

[wiki_rag]: https://en.wikipedia.org/wiki/Prompt_engineering#Retrieval-augmented_generation
[openai_token]: https://platform.openai.com/docs/introduction/tokens
[wiki_embedding]: https://en.wikipedia.org/wiki/Sentence_embedding

[^1]: De fleste tilbydere bruker i dag vektordatabaser som søkemotor i deres
_KBS_ oppsett.